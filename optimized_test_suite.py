#!/usr/bin/env python3
"""
Comprehensive Test Suite - KompletnÃ­ testovacÃ­ sada pro celÃ½ projekt
"""

import pytest
import asyncio
import json
import tempfile
import os
from pathlib import Path
import sys

# PÅ™idej projekt do Python path
sys.path.insert(0, str(Path(__file__).parent))

from core.main import UnifiedBiohackingResearchTool
from mcp_servers.web_automation_mcp_server import WebAutomationMCPServer
from cache.unified_cache_system import UnifiedCacheManager, get_cache_manager
from unified_config import get_config
from academic_scraper import AcademicScraper
from intelligent_research_orchestrator import IntelligentResearchOrchestrator

class TestUnifiedSystem:
    """Testy pro hlavnÃ­ unified systÃ©m"""

    @pytest.mark.asyncio
    async def test_basic_research_functionality(self):
        """Test zÃ¡kladnÃ­ funkcionalita vÃ½zkumu"""
        async with UnifiedBiohackingResearchTool("test_user", verbose=True) as tool:
            result = await tool.research(
                query="BPC-157 peptide research",
                research_type="quick",
                evidence_level="medium"
            )

            assert result["success"] is True
            assert "query" in result
            assert result["query"] == "BPC-157 peptide research"
            print("âœ… Basic research functionality test passed")

    @pytest.mark.asyncio
    async def test_performance_stats(self):
        """Test sledovÃ¡nÃ­ vÃ½konu"""
        async with UnifiedBiohackingResearchTool("test_user") as tool:
            # ProveÄ nÄ›kolik dotazÅ¯
            for i in range(3):
                await tool.research(f"test query {i}")

            stats = tool.get_performance_stats()
            assert stats["queries_processed"] == 3
            assert stats["total_time"] > 0
            print("âœ… Performance stats test passed")

class TestCacheSystem:
    """Testy pro cache systÃ©m"""

    def setup_method(self):
        """Setup pro kaÅ¾dÃ½ test"""
        self.temp_dir = tempfile.mkdtemp()
        self.cache = UnifiedCacheManager(cache_dir=self.temp_dir)

    @pytest.mark.asyncio
    async def test_cache_set_get(self):
        """Test zÃ¡kladnÃ­ cache operace"""
        test_data = {"test": "data", "number": 42}

        # UloÅ¾ do cache
        success = await self.cache.set("test_key", test_data, ttl=3600)
        assert success is True

        # NaÄti z cache
        retrieved = await self.cache.get("test_key")
        assert retrieved == test_data
        print("âœ… Cache set/get test passed")

    @pytest.mark.asyncio
    async def test_cache_expiration(self):
        """Test expirace cache"""
        # UloÅ¾ s krÃ¡tkÃ½m TTL
        await self.cache.set("expire_test", "data", ttl=1)

        # Zkontroluj, Å¾e data jsou tam
        result = await self.cache.get("expire_test")
        assert result == "data"

        # PoÄkej na expiraci
        await asyncio.sleep(2)

        # Data by mÄ›la bÃ½t expirovanÃ¡
        result = await self.cache.get("expire_test")
        assert result is None
        print("âœ… Cache expiration test passed")

    @pytest.mark.asyncio
    async def test_cache_stats(self):
        """Test cache statistik"""
        # PÅ™idej nÄ›jakÃ¡ data
        await self.cache.set("stats_test", "data")
        await self.cache.get("stats_test")

        stats = await self.cache.get_stats()
        assert "total_entries" in stats
        assert stats["total_entries"] >= 1
        print("âœ… Cache stats test passed")

class TestWebAutomationMCP:
    """Testy pro Web Automation MCP Server"""

    def setup_method(self):
        """Setup pro kaÅ¾dÃ½ test"""
        self.server = WebAutomationMCPServer()

    @pytest.mark.asyncio
    async def test_server_initialization(self):
        """Test inicializace serveru"""
        assert self.server.server is not None
        assert self.server.ssl_context is not None
        print("âœ… MCP Server initialization test passed")

    @pytest.mark.asyncio
    async def test_session_creation(self):
        """Test vytvoÅ™enÃ­ HTTP session"""
        session = await self.server._get_session()
        assert session is not None
        assert not session.closed

        # Cleanup
        await self.server.cleanup()
        print("âœ… Session creation test passed")

class TestAcademicScraper:
    """Testy pro Academic Scraper"""

    @pytest.mark.asyncio
    async def test_scraper_initialization(self):
        """Test inicializace scraperu"""
        async with AcademicScraper() as scraper:
            assert scraper.session is not None
            assert not scraper.session.closed
        print("âœ… Academic scraper initialization test passed")

    @pytest.mark.asyncio
    async def test_comprehensive_search_structure(self):
        """Test struktury vÃ½sledkÅ¯ comprehensive search"""
        async with AcademicScraper() as scraper:
            # Mock test - nebudeme dÄ›lat skuteÄnÃ© HTTP requesty v testech
            result = {
                'query': 'test query',
                'wikipedia': [],
                'pubmed': [],
                'total_results': 0,
                'timestamp': 12345
            }

            assert 'query' in result
            assert 'wikipedia' in result
            assert 'pubmed' in result
            assert 'total_results' in result
        print("âœ… Comprehensive search structure test passed")

class TestIntelligentOrchestrator:
    """Testy pro Intelligent Research Orchestrator"""

    @pytest.mark.asyncio
    async def test_orchestrator_initialization(self):
        """Test inicializace orchestrÃ¡toru"""
        orchestrator = IntelligentResearchOrchestrator()
        assert orchestrator.cache_manager is not None
        assert orchestrator.research_stats["total_queries"] == 0
        print("âœ… Orchestrator initialization test passed")

    @pytest.mark.asyncio
    async def test_safety_assessment(self):
        """Test bezpeÄnostnÃ­ho hodnocenÃ­"""
        orchestrator = IntelligentResearchOrchestrator()

        # Mock data s bezpeÄnostnÃ­mi klÃ­ÄovÃ½mi slovy
        mock_results = {
            "all_results": [
                {
                    "title": "Safety study of test compound",
                    "snippet": "This study examines side effects and toxicity",
                    "confidence": 0.9
                }
            ]
        }

        safety_info = await orchestrator._assess_safety("test query", mock_results)

        assert "risk_level" in safety_info
        assert "safety_mentions" in safety_info
        assert "recommendation" in safety_info
        print("âœ… Safety assessment test passed")

class TestConfiguration:
    """Testy pro konfiguraÄnÃ­ systÃ©m"""

    def test_config_loading(self):
        """Test naÄÃ­tÃ¡nÃ­ konfigurace"""
        config = get_config()
        assert config is not None

        # Test zÃ¡kladnÃ­ch sekcÃ­
        assert config.get("database") is not None
        assert config.get("api") is not None
        assert config.get("scraping") is not None
        print("âœ… Configuration loading test passed")

    def test_config_get_set(self):
        """Test get/set operacÃ­ konfigurace"""
        config = get_config()

        # Test get
        rate_limit = config.get("api.rate_limit")
        assert rate_limit is not None

        # Test set
        config.set("test.value", "test_data")
        retrieved = config.get("test.value")
        assert retrieved == "test_data"
        print("âœ… Configuration get/set test passed")

@pytest.mark.asyncio
async def test_integration_basic_workflow():
    """IntegraÄnÃ­ test zÃ¡kladnÃ­ho workflow"""
    # Test celÃ©ho workflow od zaÄÃ¡tku do konce
    async with UnifiedBiohackingResearchTool("integration_test") as tool:
        result = await tool.research(
            query="integration test",
            research_type="quick",
            evidence_level="medium",
            output_format="json"
        )

        # Kontrola zÃ¡kladnÃ­ struktury odpovÄ›di
        assert isinstance(result, dict)
        assert "success" in result
        assert "query" in result

        # Kontrola performance stats
        stats = tool.get_performance_stats()
        assert stats["queries_processed"] >= 1

    print("âœ… Integration workflow test passed")

def run_performance_benchmark():
    """SpustÃ­ benchmark test vÃ½konu"""
    import time

    async def benchmark():
        start_time = time.time()

        async with UnifiedBiohackingResearchTool("benchmark_test") as tool:
            # ProveÄ sÃ©rii testÅ¯
            tasks = []
            for i in range(5):
                task = tool.research(f"benchmark test {i}", research_type="quick")
                tasks.append(task)

            results = await asyncio.gather(*tasks)

            end_time = time.time()
            total_time = end_time - start_time

            successful = sum(1 for r in results if r.get("success"))

            print(f"\nğŸ“Š Performance Benchmark Results:")
            print(f"   Total requests: {len(tasks)}")
            print(f"   Successful requests: {successful}")
            print(f"   Total time: {total_time:.2f}s")
            print(f"   Average time per request: {total_time/len(tasks):.2f}s")
            print(f"   Requests per second: {len(tasks)/total_time:.2f}")

    asyncio.run(benchmark())

if __name__ == "__main__":
    print("ğŸ§ª Running Comprehensive Test Suite...")
    print("=" * 60)

    # SpusÅ¥ testy
    pytest.main([__file__, "-v", "--tb=short"])

    print("\n" + "=" * 60)
    print("ğŸš€ Running Performance Benchmark...")
    run_performance_benchmark()

    print("\nâœ… All tests completed!")
