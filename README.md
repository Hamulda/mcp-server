# ResearchTool

PokroÄilÃ½ nÃ¡stroj pro vÃ½zkum a analÃ½zu akademickÃ½ch zdrojÅ¯ s optimalizacÃ­ nÃ¡kladÅ¯ a vysokÃ½m vÃ½konem.

## Funkce

- ğŸ” **InteligentnÃ­ vyhledÃ¡vÃ¡nÃ­** - Google Scholar, PubMed, Semantic Scholar
- ğŸ§  **AI analÃ½za** - Gemini API pro zpracovÃ¡nÃ­ a sumarizaci textÅ¯
- ğŸ’° **Optimalizace nÃ¡kladÅ¯** - PokroÄilÃ© sledovÃ¡nÃ­ a omezovÃ¡nÃ­ vÃ½dajÅ¯
- âš¡ **VysokÃ½ vÃ½kon** - ParalelnÃ­ zpracovÃ¡nÃ­ a inteligentnÃ­ cache
- ğŸ“Š **Monitoring** - Grafana dashboardy a metriky
- ğŸ¯ **Specializace na medicÃ­nu** - OptimalizovÃ¡no pro nootropika, peptidy, medikace

## RychlÃ½ start

### PoÅ¾adavky
- Python 3.8+
- Docker a Docker Compose (pro monitoring)
- Gemini API klÃ­Ä

### Instalace

1. Klonujte repozitÃ¡Å™:
```bash
git clone https://github.com/yourusername/ResearchTool.git
cd ResearchTool
```

2. VytvoÅ™te virtuÃ¡lnÃ­ prostÅ™edÃ­:
```bash
python -m venv .venv
source .venv/bin/activate  # Na Windows: .venv\Scripts\activate
```

3. Nainstalujte zÃ¡vislosti:
```bash
pip install -r requirements.txt
```

4. Nastavte API klÃ­Äe:
```bash
cp config.py config_personal.py
# Upravte config_personal.py s vaÅ¡imi API klÃ­Äi
```

### SpuÅ¡tÄ›nÃ­

#### Streamlit UI
```bash
streamlit run streamlit_app.py
```

#### Command Line
```bash
python main_fast.py
```

#### S monitoringem (Docker)
```bash
docker-compose up -d
# Grafana: http://localhost:3000 (admin/admin)
# Prometheus: http://localhost:9090
```

## Konfigurace

HlavnÃ­ konfigurace v `config_personal.py`:

- `DAILY_COST_LIMIT`: DennÃ­ limit nÃ¡kladÅ¯
- `GEMINI_RATE_LIMIT`: OmezenÃ­ requestÅ¯ za minutu
- `MAX_CONCURRENT_REQUESTS`: ParalelnÃ­ poÅ¾adavky
- `LOCAL_MODE`: Optimalizace pro lokÃ¡lnÃ­ pouÅ¾itÃ­

## Struktura projektu

```
â”œâ”€â”€ streamlit_app.py           # Web UI
â”œâ”€â”€ main_fast.py              # CLI rozhranÃ­
â”œâ”€â”€ research_engine.py        # HlavnÃ­ vÃ½zkumnÃ½ engine
â”œâ”€â”€ gemini_manager.py         # Gemini API management
â”œâ”€â”€ web_scraper.py           # Web scraping
â”œâ”€â”€ academic_scraper.py      # AkademickÃ© zdroje
â”œâ”€â”€ text_analyzer.py         # AnalÃ½za textu
â”œâ”€â”€ cost_tracker.py          # SledovÃ¡nÃ­ nÃ¡kladÅ¯
â”œâ”€â”€ database_manager.py      # DatabÃ¡zovÃ© operace
â”œâ”€â”€ monitoring/              # Grafana a Prometheus config
â””â”€â”€ tests/                   # Testy
```

## Optimalizace nÃ¡kladÅ¯

- **Token optimalizace**: InteligentnÃ­ zkracovÃ¡nÃ­ textÅ¯
- **Caching**: PerzistentnÃ­ cache pro opakovanÃ© dotazy
- **Batch processing**: SkupinovÃ© zpracovÃ¡nÃ­ pro efektivitu
- **Rate limiting**: Kontrola frekvence API volÃ¡nÃ­

## TestovÃ¡nÃ­

```bash
# JednotkovÃ© testy
pytest test_core_components.py

# IntegraÄnÃ­ testy
pytest test_integration.py

# VÅ¡echny testy
pytest
```

## Monitoring

Projekt obsahuje kompletnÃ­ monitoring stack:

- **Prometheus**: SbÄ›r metrik
- **Grafana**: Vizualizace dashboardÅ¯
- **Custom metriky**: NÃ¡klady, vÃ½kon, chyby

## VÃ½voj

### Pre-commit hooks
```bash
pip install -r requirements-dev.txt
pre-commit install
```

### PÅ™idÃ¡nÃ­ novÃ©ho scraperu
1. VytvoÅ™te tÅ™Ã­du dÄ›dÃ­cÃ­ z `BaseScraper`
2. Implementujte `_scrape_search_results`
3. PÅ™idejte do `DEFAULT_SOURCES` v config

## Licence

MIT License - viz LICENSE soubor

## Podpora

Pro otÃ¡zky a problÃ©my vytvoÅ™te GitHub issue.
