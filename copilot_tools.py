#!/usr/bin/env python3
"""
Unified Copilot Tools - Konsolidovan√© n√°stroje pro GitHub Copilota
CONSOLIDATED - slouƒçeno smart_mcp_tools.py + advanced_copilot_mcp.py + copilot_mcp_interface.py + github_copilot_mcp_tools.py
"""

import sys
import os
import json
import re
import hashlib
import sqlite3
import logging
import ast
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from pathlib import Path

sys.path.append('/Users/vojtechhamada/PycharmProjects/PythonProject2')

try:
    from unified_cache_system import get_unified_cache
    from biohacking_research_engine import BiohackingResearchEngine
    from local_ai_adapter import M1OptimizedOllamaClient
    DEPS_AVAILABLE = True
except ImportError:
    DEPS_AVAILABLE = False
    def get_unified_cache():
        return None

logger = logging.getLogger(__name__)

@dataclass
class ConversationContext:
    """Kontext aktu√°ln√≠ konverzace (z advanced_copilot_mcp.py)"""
    topic: str
    user_intent: str
    complexity_level: str
    domain: str
    technical_depth: str
    user_expertise: str
    required_tools: List[str]
    token_budget: str

@dataclass
class CodePattern:
    """N√°vrhov√Ω vzor k√≥du pro optimalizaci (z github_copilot_mcp_tools.py)"""
    template: str
    use_cases: List[str]
    token_savings: float
    complexity_reduction: float = 0.0
    maintainability_score: float = 0.0

@dataclass
class CompoundValidation:
    """Validace biohackingov√Ωch l√°tek"""
    compound_name: str
    research_status: str
    common_dosage: str
    main_risks: List[str]
    confidence_score: float
    sources: List[str]

@dataclass
class SafetyIssue:
    """Bezpeƒçnostn√≠ probl√©m v k√≥du"""
    issue_type: str
    severity: str
    location: str
    description: str
    fix_suggestion: str

class BiohackingCompoundValidator:
    """
    Nov√Ω n√°stroj: Valid√°tor Biohackingov√Ωch l√°tek
    Okam≈æit√° kontrola fakt≈Ø p≈ô√≠mo v k√≥du
    """

    def __init__(self):
        self.cache = get_unified_cache() if DEPS_AVAILABLE else None
        self.research_engine = None
        self.compound_database = self._load_compound_database()

    def _load_compound_database(self) -> Dict[str, Dict]:
        """Naƒçte datab√°zi zn√°m√Ωch l√°tek"""
        return {
            "bpc-157": {
                "research_status": "Klinick√© studie f√°ze II",
                "common_dosage": "250-500 mcg/den",
                "main_risks": ["N√≠zk√©, mo≈æn√© interakce s antikoagulaƒçn√≠mi l√©ky"],
                "confidence": 0.8,
                "category": "peptide"
            },
            "tb-500": {
                "research_status": "Preklinick√© studie",
                "common_dosage": "2-5 mg t√Ωdnƒõ",
                "main_risks": ["Nedostateƒçn√° data o dlouhodob√Ωch √∫ƒçinc√≠ch"],
                "confidence": 0.6,
                "category": "peptide"
            },
            "nad+": {
                "research_status": "Rozs√°hl√© preklinick√© + nƒõkter√© klinick√©",
                "common_dosage": "250-500 mg/den (prekurzory)",
                "main_risks": ["Mo≈æn√© gastrointestin√°ln√≠ probl√©my p≈ôi vysok√Ωch d√°vk√°ch"],
                "confidence": 0.7,
                "category": "supplement"
            },
            "nmn": {
                "research_status": "Klinick√© studie f√°ze I-II",
                "common_dosage": "250-1000 mg/den",
                "main_risks": ["Minim√°ln√≠ vedlej≈°√≠ √∫ƒçinky, mo≈æn√° interakce s diabetick√Ωmi l√©ky"],
                "confidence": 0.75,
                "category": "supplement"
            }
        }

    async def validate_compound(self, compound_name: str) -> CompoundValidation:
        """Validuje biohackingovou l√°tku a vrac√≠ shrnut√≠"""

        compound_lower = compound_name.lower().strip()

        # Zkontroluj lok√°ln√≠ datab√°zi
        if compound_lower in self.compound_database:
            data = self.compound_database[compound_lower]
            return CompoundValidation(
                compound_name=compound_name,
                research_status=data["research_status"],
                common_dosage=data["common_dosage"],
                main_risks=data["main_risks"],
                confidence_score=data["confidence"],
                sources=["Internal database"]
            )

        # Pokud nen√≠ v datab√°zi, zkus online v√Ωzkum
        if self.research_engine:
            try:
                research_result = await self.research_engine.quick_compound_lookup(compound_name)
                return CompoundValidation(
                    compound_name=compound_name,
                    research_status=research_result.get("status", "Nezn√°m√Ω"),
                    common_dosage=research_result.get("dosage", "Nen√≠ k dispozici"),
                    main_risks=research_result.get("risks", ["Nedostateƒçn√© √∫daje"]),
                    confidence_score=research_result.get("confidence", 0.3),
                    sources=research_result.get("sources", [])
                )
            except Exception as e:
                logger.warning(f"Research engine failed for {compound_name}: {e}")

        # Fallback pro nezn√°m√© l√°tky
        return CompoundValidation(
            compound_name=compound_name,
            research_status="‚ö†Ô∏è Nezn√°m√° l√°tka - vy≈æaduje manu√°ln√≠ v√Ωzkum",
            common_dosage="Nen√≠ k dispozici",
            main_risks=["Nezn√°m√© riziko", "Nedostateƒçn√© √∫daje o bezpeƒçnosti"],
            confidence_score=0.1,
            sources=[]
        )

class CodePatternOptimizer:
    """
    Nov√Ω n√°stroj: Optimaliz√°tor N√°vrhov√Ωch Vzor≈Ø
    Detekuje a navrhuje optimalizovan√© vzory
    """

    def __init__(self):
        self.patterns = self._load_code_patterns()

    def _load_code_patterns(self) -> Dict[str, CodePattern]:
        """Naƒçte optimalizovan√© n√°vrhov√© vzory"""
        return {
            "async_context_manager": CodePattern(
                template='''class {class_name}:
    """AI-enabled component with proper resource management"""
    
    async def __aenter__(self):
        self.client = await self._init_client()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if hasattr(self, 'client'):
            await self.client.close()''',
                use_cases=["API clients", "Database connections", "AI models"],
                token_savings=0.6,
                complexity_reduction=0.4
            ),

            "cached_research_function": CodePattern(
                template='''@cached_research_function
async def {function_name}(query: str, **kwargs) -> Dict[str, Any]:
    """Cached research function with automatic retry"""
    cache_key = f"{function_name}_{hash(query)}"
    
    # Try cache first
    if cached_result := await self.cache.get(cache_key):
        return cached_result
        
    # Execute research
    try:
        result = await self._execute_research(query, **kwargs)
        await self.cache.set(cache_key, result, ttl=3600)
        return result
        
    except Exception as e:
        logger.error(f"Research failed: {e}")
        raise ResearchError(f"Failed to {function_name}: {e}")''',
                use_cases=["Research functions", "Data processing", "API calls"],
                token_savings=0.75,
                complexity_reduction=0.5
            ),

            "data_validation_pattern": CodePattern(
                template='''@dataclass
class {class_name}:
    """Validated data structure for {purpose}"""
    {fields}
    
    def __post_init__(self):
        """Validate data after initialization"""
        self._validate_fields()
    
    def _validate_fields(self):
        """Validate all fields with proper error messages"""
        {validation_logic}''',
                use_cases=["Data structures", "API models", "Configuration"],
                token_savings=0.60,
                complexity_reduction=0.3
            )
        }

    def analyze_code_for_patterns(self, code: str) -> List[Dict[str, Any]]:
        """Analyzuje k√≥d a navrhuje optimalizace"""

        suggestions = []

        try:
            tree = ast.parse(code)

            for node in ast.walk(tree):
                # Detekce kandid√°t≈Ø na async context manager
                if isinstance(node, ast.ClassDef):
                    if self._has_init_method(node) and self._uses_resources(code):
                        suggestions.append({
                            "pattern": "async_context_manager",
                            "location": f"Class {node.name}",
                            "reason": "Class appears to manage resources",
                            "template": self.patterns["async_context_manager"].template,
                            "token_savings": self.patterns["async_context_manager"].token_savings
                        })

                # Detekce funkc√≠ vhodn√Ωch pro caching
                elif isinstance(node, ast.FunctionDef):
                    if self._is_research_function(node, code):
                        suggestions.append({
                            "pattern": "cached_research_function",
                            "location": f"Function {node.name}",
                            "reason": "Function performs research/API calls",
                            "template": self.patterns["cached_research_function"].template,
                            "token_savings": self.patterns["cached_research_function"].token_savings
                        })

        except SyntaxError:
            logger.warning("Could not parse code for pattern analysis")

        return suggestions

    def _has_init_method(self, class_node: ast.ClassDef) -> bool:
        """Zkontroluje, zda t≈ô√≠da m√° __init__ metodu"""
        return any(isinstance(node, ast.FunctionDef) and node.name == "__init__"
                  for node in class_node.body)

    def _uses_resources(self, code: str) -> bool:
        """Zkontroluje, zda k√≥d pou≈æ√≠v√° extern√≠ zdroje"""
        resource_keywords = ["client", "connection", "session", "api", "database"]
        return any(keyword in code.lower() for keyword in resource_keywords)

    def _is_research_function(self, func_node: ast.FunctionDef, code: str) -> bool:
        """Zkontroluje, zda funkce prov√°d√≠ v√Ωzkum/API vol√°n√≠"""
        research_keywords = ["research", "search", "fetch", "query", "request"]
        func_name = func_node.name.lower()
        return any(keyword in func_name for keyword in research_keywords)

class AsyncSafetyGuard:
    """
    Nov√Ω n√°stroj: Ochrana Asynchronn√≠ho K√≥du
    Specializovan√Ω linter pro async k√≥d
    """

    def __init__(self):
        self.async_issues = []

    def analyze_async_code(self, code: str) -> List[SafetyIssue]:
        """Analyzuje asynchronn√≠ k√≥d na bezpeƒçnostn√≠ probl√©my"""

        issues = []

        try:
            tree = ast.parse(code)

            for node in ast.walk(tree):
                # Detekce await na nespr√°vn√Ωch funkc√≠ch
                if isinstance(node, ast.Await):
                    issues.extend(self._check_await_usage(node, code))

                # Detekce blokuj√≠c√≠ch vol√°n√≠ v async funkc√≠ch
                elif isinstance(node, ast.Call):
                    issues.extend(self._check_blocking_calls(node, code))

                # Detekce chybƒõj√≠c√≠ch await
                elif isinstance(node, ast.Call):
                    issues.extend(self._check_missing_await(node, code))

        except SyntaxError as e:
            issues.append(SafetyIssue(
                issue_type="syntax_error",
                severity="high",
                location=f"Line {e.lineno}",
                description=f"Syntax error in async code: {e.msg}",
                fix_suggestion="Fix syntax error before async analysis"
            ))

        return issues

    def _check_await_usage(self, await_node: ast.Await, code: str) -> List[SafetyIssue]:
        """Zkontroluje spr√°vn√© pou≈æit√≠ await"""
        issues = []

        # Zde by byla implementace detekce nespr√°vn√©ho await
        # Pro demonstraci p≈ôid√°m z√°kladn√≠ kontrolu

        return issues

    def _check_blocking_calls(self, call_node: ast.Call, code: str) -> List[SafetyIssue]:
        """Zkontroluje blokuj√≠c√≠ vol√°n√≠"""
        issues = []

        blocking_functions = ["time.sleep", "requests.get", "requests.post"]

        if isinstance(call_node.func, ast.Attribute):
            func_name = f"{call_node.func.value.id}.{call_node.func.attr}"
            if func_name in blocking_functions:
                issues.append(SafetyIssue(
                    issue_type="blocking_call",
                    severity="medium",
                    location=f"Line {call_node.lineno}",
                    description=f"Blocking call {func_name} in async context",
                    fix_suggestion=f"Use async alternative: {self._get_async_alternative(func_name)}"
                ))

        return issues

    def _check_missing_await(self, call_node: ast.Call, code: str) -> List[SafetyIssue]:
        """Zkontroluje chybƒõj√≠c√≠ await"""
        issues = []

        # Detekce vol√°n√≠ async funkc√≠ bez await
        async_functions = ["aiohttp.get", "asyncio.sleep", "client.generate_response"]

        if isinstance(call_node.func, ast.Attribute):
            func_name = f"{call_node.func.value.id}.{call_node.func.attr}"
            if any(async_func in func_name for async_func in async_functions):
                # Zkontroluj, zda nen√≠ v await kontextu
                issues.append(SafetyIssue(
                    issue_type="missing_await",
                    severity="high",
                    location=f"Line {call_node.lineno}",
                    description=f"Async function {func_name} called without await",
                    fix_suggestion=f"Add await: await {func_name}(...)"
                ))

        return issues

    def _get_async_alternative(self, blocking_func: str) -> str:
        """Vr√°t√≠ async alternativu k blokuj√≠c√≠ funkci"""
        alternatives = {
            "time.sleep": "asyncio.sleep",
            "requests.get": "aiohttp.ClientSession.get",
            "requests.post": "aiohttp.ClientSession.post"
        }
        return alternatives.get(blocking_func, "Use async alternative")

class PrivacyLeakDetector:
    """
    Nov√Ω n√°stroj: Detektor √öniku Citliv√Ωch Dat
    Hled√° potenci√°ln√≠ √∫niky citliv√Ωch informac√≠
    """

    def __init__(self):
        self.sensitive_patterns = self._load_sensitive_patterns()

    def _load_sensitive_patterns(self) -> Dict[str, List[str]]:
        """Naƒçte vzory citliv√Ωch dat"""
        return {
            "api_keys": [
                r"api[_-]?key['\"]?\s*[=:]\s*['\"][a-zA-Z0-9]{20,}['\"]",
                r"secret[_-]?key['\"]?\s*[=:]\s*['\"][a-zA-Z0-9]{20,}['\"]",
                r"access[_-]?token['\"]?\s*[=:]\s*['\"][a-zA-Z0-9]{20,}['\"]"
            ],
            "passwords": [
                r"password['\"]?\s*[=:]\s*['\"][^'\"]{8,}['\"]",
                r"passwd['\"]?\s*[=:]\s*['\"][^'\"]{8,}['\"]"
            ],
            "personal_data": [
                r"email['\"]?\s*[=:]\s*['\"][^'\"]*@[^'\"]*['\"]",
                r"phone['\"]?\s*[=:]\s*['\"][0-9+\-\s()]{10,}['\"]"
            ],
            "database_urls": [
                r"database[_-]?url['\"]?\s*[=:]\s*['\"][^'\"]*://[^'\"]*['\"]",
                r"db[_-]?connection['\"]?\s*[=:]\s*['\"][^'\"]*://[^'\"]*['\"]"
            ]
        }

    def scan_for_privacy_leaks(self, code: str, file_path: str = "") -> List[SafetyIssue]:
        """Skenuje k√≥d na √∫niky citliv√Ωch dat"""

        issues = []
        lines = code.split('\n')

        for line_num, line in enumerate(lines, 1):
            for category, patterns in self.sensitive_patterns.items():
                for pattern in patterns:
                    if re.search(pattern, line, re.IGNORECASE):
                        issues.append(SafetyIssue(
                            issue_type="privacy_leak",
                            severity="high",
                            location=f"{file_path}:{line_num}",
                            description=f"Potential {category} leak: {line.strip()}",
                            fix_suggestion=self._get_privacy_fix_suggestion(category)
                        ))

        return issues

    def _get_privacy_fix_suggestion(self, category: str) -> str:
        """Vr√°t√≠ n√°vrh na opravu √∫niku"""
        suggestions = {
            "api_keys": "Move to environment variables or unified_config.py",
            "passwords": "Use environment variables or secure vault",
            "personal_data": "Ensure data is properly anonymized or encrypted",
            "database_urls": "Move to configuration file or environment"
        }
        return suggestions.get(category, "Remove sensitive data from source code")

class CopilotCodeAnalyzer:
    """
    Analyz√°tor k√≥du pro GitHub Copilota (z github_copilot_mcp_tools.py)
    Integrovan√Ω s nov√Ωmi n√°stroji
    """

    def __init__(self):
        self.compound_validator = BiohackingCompoundValidator()
        self.pattern_optimizer = CodePatternOptimizer()
        self.async_guard = AsyncSafetyGuard()
        self.privacy_detector = PrivacyLeakDetector()

    async def comprehensive_code_analysis(
        self,
        code: str,
        file_path: str = "",
        context: str = ""
    ) -> Dict[str, Any]:
        """Komplexn√≠ anal√Ωza k√≥du s v≈°emi n√°stroji"""

        analysis_results = {
            "file_path": file_path,
            "analysis_timestamp": datetime.now().isoformat(),
            "context": context
        }

        # 1. Biohacking validace
        compounds = self._extract_compounds_from_code(code)
        if compounds:
            compound_validations = []
            for compound in compounds:
                validation = await self.compound_validator.validate_compound(compound)
                compound_validations.append(validation.__dict__)
            analysis_results["compound_validations"] = compound_validations

        # 2. Pattern optimalizace
        pattern_suggestions = self.pattern_optimizer.analyze_code_for_patterns(code)
        analysis_results["pattern_suggestions"] = pattern_suggestions

        # 3. Async safety
        if "async" in code or "await" in code:
            async_issues = self.async_guard.analyze_async_code(code)
            analysis_results["async_safety_issues"] = [issue.__dict__ for issue in async_issues]

        # 4. Privacy leaks
        privacy_issues = self.privacy_detector.scan_for_privacy_leaks(code, file_path)
        analysis_results["privacy_issues"] = [issue.__dict__ for issue in privacy_issues]

        # 5. Overall score
        analysis_results["overall_quality_score"] = self._calculate_quality_score(analysis_results)

        return analysis_results

    def _extract_compounds_from_code(self, code: str) -> List[str]:
        """Extrahuje n√°zvy l√°tek z k√≥du"""

        # Zn√°m√© biohacking l√°tky
        known_compounds = [
            "bpc-157", "tb-500", "ghrp-6", "ghrp-2", "ipamorelin",
            "mod-grf", "cjc-1295", "nad+", "nmn", "resveratrol",
            "metformin", "rapamycin", "berberine", "curcumin"
        ]

        found_compounds = []
        code_lower = code.lower()

        for compound in known_compounds:
            if compound in code_lower:
                found_compounds.append(compound)

        return found_compounds

    def _calculate_quality_score(self, analysis: Dict[str, Any]) -> float:
        """Vypoƒç√≠t√° celkov√© sk√≥re kvality k√≥du"""

        score = 10.0  # Zaƒç√≠n√°me s maxim√°ln√≠m sk√≥re

        # Sr√°≈æky za probl√©my
        privacy_issues = len(analysis.get("privacy_issues", []))
        async_issues = len(analysis.get("async_safety_issues", []))

        score -= privacy_issues * 2.0  # Tƒõ≈æk√© sr√°≈æky za privacy
        score -= async_issues * 1.0    # St≈ôedn√≠ sr√°≈æky za async probl√©my

        # Bonusy za optimalizace
        pattern_suggestions = len(analysis.get("pattern_suggestions", []))
        if pattern_suggestions > 0:
            score += 0.5  # Mal√Ω bonus za mo≈ænosti optimalizace

        return max(0.0, min(10.0, score))

class UnifiedCopilotInterface:
    """
    Sjednocen√© rozhran√≠ pro v≈°echny Copilot n√°stroje
    CONSOLIDATED - hlavn√≠ interface t≈ô√≠da
    """

    def __init__(self):
        # Core components
        self.cache = get_unified_cache() if DEPS_AVAILABLE else None
        self.session_id = f"unified_copilot_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        # Analyzers and tools
        self.code_analyzer = CopilotCodeAnalyzer()
        self.compound_validator = BiohackingCompoundValidator()
        self.pattern_optimizer = CodePatternOptimizer()
        self.async_guard = AsyncSafetyGuard()
        self.privacy_detector = PrivacyLeakDetector()

        # Context management (z smart_mcp_tools.py)
        self.context_db = self._init_context_db()

        # Context patterns (z advanced_copilot_mcp.py)
        self.context_patterns = {
            'biohacking': {
                'keywords': ['peptide', 'nootropic', 'supplement', 'biohacking', 'longevity', 'performance'],
                'tools': ['biohacking_research', 'academic_analysis', 'safety_check'],
                'token_priority': 'high_structure'
            },
            'coding': {
                'keywords': ['python', 'javascript', 'code', 'function', 'class', 'debug'],
                'tools': ['code_analysis', 'documentation_scan', 'pattern_recognition'],
                'token_priority': 'high_precision'
            },
            'research': {
                'keywords': ['research', 'study', 'analysis', 'paper', 'academic', 'scientific'],
                'tools': ['intelligent_search', 'context_persistence', 'academic_analysis'],
                'token_priority': 'high_structure'
            }
        }

    def _init_context_db(self) -> str:
        """Inicializuje datab√°zi kontextu"""
        cache_dir = "/Users/vojtechhamada/PycharmProjects/PythonProject2/cache"
        os.makedirs(cache_dir, exist_ok=True)

        db_path = os.path.join(cache_dir, "unified_copilot_cache.db")
        conn = sqlite3.connect(db_path)

        conn.execute('''
            CREATE TABLE IF NOT EXISTS search_cache (
                query TEXT PRIMARY KEY,
                results TEXT,
                timestamp DATETIME,
                source TEXT
            )
        ''')

        conn.execute('''
            CREATE TABLE IF NOT EXISTS research_context (
                session_id TEXT,
                context_key TEXT,
                context_data TEXT,
                timestamp DATETIME,
                PRIMARY KEY (session_id, context_key)
            )
        ''')

        conn.execute('''
            CREATE TABLE IF NOT EXISTS code_analysis_cache (
                file_hash TEXT PRIMARY KEY,
                analysis_result TEXT,
                timestamp DATETIME
            )
        ''')

        conn.close()
        return db_path

    async def analyze_conversation_context(self, message: str) -> ConversationContext:
        """Analyzuje kontext konverzace a vybere vhodn√© n√°stroje"""

        message_lower = message.lower()

        # Detekce dom√©ny
        domain = "general"
        for domain_name, domain_data in self.context_patterns.items():
            if any(keyword in message_lower for keyword in domain_data['keywords']):
                domain = domain_name
                break

        # Detekce slo≈æitosti
        complexity_indicators = {
            'beginner': ['how to', 'what is', 'simple', 'basic', 'start'],
            'intermediate': ['implement', 'optimize', 'compare', 'analysis'],
            'advanced': ['architecture', 'performance', 'scalability', 'deep dive'],
            'expert': ['research', 'cutting-edge', 'novel', 'experimental']
        }

        complexity_level = "intermediate"  # default
        for level, indicators in complexity_indicators.items():
            if any(indicator in message_lower for indicator in indicators):
                complexity_level = level
                break

        # Detekce √∫myslu
        intent_patterns = {
            'research': ['research', 'find', 'search', 'investigate'],
            'implement': ['implement', 'code', 'build', 'create'],
            'debug': ['debug', 'fix', 'error', 'problem'],
            'optimize': ['optimize', 'improve', 'performance', 'faster'],
            'learn': ['learn', 'understand', 'explain', 'teach']
        }

        user_intent = "general"
        for intent, patterns in intent_patterns.items():
            if any(pattern in message_lower for pattern in patterns):
                user_intent = intent
                break

        return ConversationContext(
            topic=domain,
            user_intent=user_intent,
            complexity_level=complexity_level,
            domain=domain,
            technical_depth="medium",
            user_expertise=complexity_level,
            required_tools=self.context_patterns.get(domain, {}).get('tools', []),
            token_budget=self.context_patterns.get(domain, {}).get('token_priority', 'medium')
        )

    async def smart_code_analysis(
        self,
        code: str,
        file_path: str = "",
        context: str = ""
    ) -> Dict[str, Any]:
        """Inteligentn√≠ anal√Ωza k√≥du s caching"""

        # Generuj hash pro caching
        code_hash = hashlib.md5(code.encode()).hexdigest()

        # Zkus cache
        cached_result = await self._get_cached_analysis(code_hash)
        if cached_result:
            logger.info("üéØ Code analysis cache hit")
            return cached_result

        # Proveƒè anal√Ωzu
        analysis = await self.code_analyzer.comprehensive_code_analysis(code, file_path, context)

        # Ulo≈æ do cache
        await self._cache_analysis(code_hash, analysis)

        return analysis

    async def validate_biohacking_compound(self, compound_name: str) -> CompoundValidation:
        """Validuje biohackingovou l√°tku"""
        return await self.compound_validator.validate_compound(compound_name)

    def suggest_code_patterns(self, code: str) -> List[Dict[str, Any]]:
        """Navrhne optimalizace k√≥du"""
        return self.pattern_optimizer.analyze_code_for_patterns(code)

    def check_async_safety(self, code: str) -> List[SafetyIssue]:
        """Zkontroluje bezpeƒçnost async k√≥du"""
        return self.async_guard.analyze_async_code(code)

    def scan_privacy_leaks(self, code: str, file_path: str = "") -> List[SafetyIssue]:
        """Naskenuje √∫niky citliv√Ωch dat"""
        return self.privacy_detector.scan_for_privacy_leaks(code, file_path)

    async def intelligent_search(
        self,
        query: str,
        sources: List[str] = None,
        max_results: int = 10
    ) -> Dict[str, Any]:
        """Inteligentn√≠ vyhled√°v√°n√≠ s token optimalizac√≠ (z smart_mcp_tools.py)"""

        cache_key = hashlib.md5(f"{query}_{sources}".encode()).hexdigest()

        # Zkontroluj cache
        conn = sqlite3.connect(self.context_db)
        cursor = conn.execute(
            "SELECT results FROM search_cache WHERE query = ? AND timestamp > ?",
            (cache_key, (datetime.now() - timedelta(hours=24)).isoformat())
        )

        cached = cursor.fetchone()
        if cached:
            conn.close()
            return json.loads(cached[0])

        # Proveƒè vyhled√°v√°n√≠
        results = await self._execute_search(query, sources, max_results)

        # Ulo≈æ do cache
        conn.execute(
            "INSERT OR REPLACE INTO search_cache (query, results, timestamp, source) VALUES (?, ?, ?, ?)",
            (cache_key, json.dumps(results), datetime.now().isoformat(), "unified_search")
        )
        conn.commit()
        conn.close()

        return results

    async def _execute_search(
        self,
        query: str,
        sources: List[str],
        max_results: int
    ) -> Dict[str, Any]:
        """Provede vyhled√°v√°n√≠ nap≈ô√≠ƒç zdroji"""

        # Z√°kladn√≠ implementace - v re√°ln√©m pou≈æit√≠ by volala
        # jednotliv√© search engines

        return {
            "query": query,
            "results": [],
            "sources_searched": sources or ["default"],
            "timestamp": datetime.now().isoformat(),
            "total_results": 0
        }

    async def _get_cached_analysis(self, code_hash: str) -> Optional[Dict[str, Any]]:
        """Z√≠sk√° cached anal√Ωzu k√≥du"""

        if not self.cache:
            return None

        try:
            cached = await self.cache.get(f"code_analysis_{code_hash}")
            return cached
        except Exception as e:
            logger.warning(f"Cache retrieval failed: {e}")
            return None

    async def _cache_analysis(self, code_hash: str, analysis: Dict[str, Any]):
        """Ulo≈æ√≠ anal√Ωzu do cache"""

        if not self.cache:
            return

        try:
            await self.cache.set(f"code_analysis_{code_hash}", analysis, ttl=3600)
        except Exception as e:
            logger.warning(f"Cache storage failed: {e}")

# Factory function
def get_copilot_tools():
    """Factory function for easy instantiation"""
    return UnifiedCopilotInterface()

# Backward compatibility aliases
SmartMCPTools = UnifiedCopilotInterface
AdvancedCopilotMCP = UnifiedCopilotInterface
CopilotMCPInterface = UnifiedCopilotInterface

# Export
__all__ = [
    'UnifiedCopilotInterface',
    'CopilotCodeAnalyzer',
    'BiohackingCompoundValidator',
    'CodePatternOptimizer',
    'AsyncSafetyGuard',
    'PrivacyLeakDetector',
    'get_copilot_tools',
    'ConversationContext',
    'CodePattern',
    'CompoundValidation',
    'SafetyIssue',
    # Backward compatibility
    'SmartMCPTools',
    'AdvancedCopilotMCP',
    'CopilotMCPInterface'
]
